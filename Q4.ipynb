{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dataframe(text):\n",
    "    text = text.strip().split('\\n')\n",
    "    data = [line.rsplit(\" \", 1) for line in text if line.strip() != \"\"]\n",
    "    df = pd.DataFrame(data, columns=['x', 'y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(df):\n",
    "    vocabulary = df['x'].unique()\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplace Smoothing \n",
    "In order to solve the a feature (word) giving zero probability (exists in test but not training set), we use Laplace Smoothing. \n",
    "\n",
    "Example: P(x’/positive)= (number of reviews with x’ and target_outcome=positive + α) / (N+ α*k) \n",
    "\n",
    "In this function, we let α=1. This ensures that the posterior probability comes out to 1/N+k rather than zero.\n",
    "\n",
    "https://www.cs.rhodes.edu/~kirlinp/courses/ai/f18/projects/proj3/naive-bayes-log-probs.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_path,file_in,file_out):\n",
    "    file_path = os.getcwd()\n",
    "\n",
    "    f = open(f\"{file_path}/{train_path}\", \"r\")\n",
    "    raw_train = f.read()\n",
    "    data = text_to_dataframe(raw_train)\n",
    "    vocab = vocabulary(data)\n",
    "\n",
    "    # Calculate prior class probabilities P(label)\n",
    "    label_counts = data['y'].value_counts().to_dict()\n",
    "    total_samples = data.shape[0]\n",
    "    prior_probs = {label: count / total_samples for label, count in label_counts.items()}\n",
    "\n",
    "    df =  data.groupby(['x', 'y']).size().reset_index(name='count')\n",
    "\n",
    "    # Calculate likelihoods P(word | label)\n",
    "    likelihoods = {}\n",
    "    for label, count in label_counts.items():\n",
    "        likelihoods[label] = {}\n",
    "\n",
    "        for word in vocab:\n",
    "            # Calculate the count of occurrences of the current word with the current label\n",
    "            filtered_data = df[(df['x'] == word) & (df['y'] == label)]\n",
    "            try:\n",
    "                word_label_count = filtered_data['count'].iat[0]\n",
    "            except:\n",
    "                word_label_count = 0\n",
    "\n",
    "            # Apply Laplace smoothing where alpha = 1\n",
    "            smoothed_likelihood = (word_label_count + 1) / (count + len(vocab))\n",
    "\n",
    "            likelihoods[label][word] = smoothed_likelihood\n",
    "\n",
    "\n",
    "    # Test sentence\n",
    "    with open(f\"{file_path}/{file_in}\", \"r\") as input_file:\n",
    "        data_devin = input_file.readlines()\n",
    "\n",
    "    # Cleaned data_devin\n",
    "    sequence = [line.strip() for line in data_devin]\n",
    "\n",
    "    # Perform Naive Bayes on test sentence\n",
    "    predictions = []\n",
    "\n",
    "    for word in sequence:\n",
    "        if word != '':\n",
    "            # simplified from: \n",
    "            # word_probs = {}\n",
    "            \n",
    "            # for label, count in label_counts.items():\n",
    "            #     if word in likelihoods[label]:\n",
    "            #         word_prob = np.log(prior_probs[label]) + np.log(likelihoods[label][word])\n",
    "            #     else:\n",
    "            #         word_prob = np.log(prior_probs[label]) + np.log(1 / (count + len(vocab)))\n",
    "            #     word_probs[label] = word_prob\n",
    "            \n",
    "            word_probs = {label: np.log(prior_probs[label]) + np.log(likelihoods[label].get(word, 1 / (count + len(vocab))))\n",
    "                          for label, count in label_counts.items()}\n",
    "\n",
    "            predicted_label = max(word_probs, key=word_probs.get)\n",
    "            predictions.append(predicted_label)\n",
    "        else:\n",
    "            predictions.append('')\n",
    "\n",
    "    # Write the output to dev.p1.out file\n",
    "    with open(f\"{file_path}/{file_out}\", 'w') as output_file:\n",
    "        for word, sentiment in zip(data_devin, predictions):\n",
    "            output_file.write(f\"{word.strip()} {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RU\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('Processing RU')\n",
    "main(\"Data/RU/train\", \"Data/RU/dev.in\",\"Data/RU/dev.p4b.out\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ES\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('Processing ES')\n",
    "main(\"Data/ES/train\", \"Data/ES/dev.in\",\"Data/ES/dev.p4b.out\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall and F scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Language: ES\n",
      "\n",
      "#Entity in gold data: 229\n",
      "#Entity in prediction: 95\n",
      "\n",
      "#Correct Entity : 75\n",
      "Entity  precision: 0.7895\n",
      "Entity  recall: 0.3275\n",
      "Entity  F: 0.4630\n",
      "\n",
      "#Correct Sentiment : 61\n",
      "Sentiment  precision: 0.6421\n",
      "Sentiment  recall: 0.2664\n",
      "Sentiment  F: 0.3765\n",
      "\n",
      "For Language: RU\n",
      "\n",
      "#Entity in gold data: 389\n",
      "#Entity in prediction: 89\n",
      "\n",
      "#Correct Entity : 77\n",
      "Entity  precision: 0.8652\n",
      "Entity  recall: 0.1979\n",
      "Entity  F: 0.3222\n",
      "\n",
      "#Correct Sentiment : 54\n",
      "Sentiment  precision: 0.6067\n",
      "Sentiment  recall: 0.1388\n",
      "Sentiment  F: 0.2259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# language \n",
    "languages = ['ES','RU']\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for language in languages:\n",
    "    print(f\"For Language: {language}\")\n",
    "    # Command to run\n",
    "    command = [\"python3\", f\"{current_dir}/EvalScript/evalResult.py\", f\"{file_path}/Data/{language}/dev.out\", f\"{file_path}/Data/{language}/dev.p4b.out\"]\n",
    "    # Run the command\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing RU\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('Processing RU')\n",
    "main(\"Data/RU/train\", \"Data/RU/test.in\",\"Data/RU/test.p4b.out\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ES\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('Processing ES')\n",
    "main(\"Data/ES/train\", \"Data/ES/test.in\",\"Data/ES/test.p4b.out\")\n",
    "print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
